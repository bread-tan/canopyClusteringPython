{"name":"Canopy Clustering using MapReduce [Hadoop (streaming)","tagline":"Canopy Clustering using MapReduce [Hadoop]","body":"Canopy Clustering using MapReduce in Hadoop\r\n=\r\n\r\nFiles Included:\r\n-\r\n<ul>\r\n<li><b>Gen.py</b></li>\r\n<li><b>Stage 1:<b>\r\n<ul><li>MapperStg1.py</li> \r\n<li>ReducerStg1.py</li></ul>\r\n<li><b>Stage 2:\r\n<ul><li>MapperStg2.py</li>\r\n<li>ReducerStg2.py</li></ul>\r\n</ul>\r\n\r\n\r\nFunctions of each of the files will be updated at a later date.\r\n\r\n\r\nTo replicate running:\r\n-\r\n\r\n1) Run gen.py to create the DataSet in dataPoints.txt\r\n2) To get a list of Canopy Centers pipe the files of Stage 1. \r\n+ + \"cat dataPoints.txt | ./mapperStg1.py | sort | ./reducerStg1.py\"\r\n+ + + Output will be a list of Canopy Centers stored in canopyCenters.txt\r\n+ + + + Output will be in the format \"1\\tDataPoint\"\r\n\r\n3) Pipe that to Stage 2 to assign each data point to a Canopy Center.\r\n+ + Output will be in the format \"CanopyCenter\\tDataPoint\"\r\n\r\n\r\nNote: \r\n+ If running on windows cmd, you have to create your own Sort function to sort input from the mapper. \r\n+ Personally, I'd recommend just using a linux OS to smoothen it all out.\r\n","google":"UA-48565082-1","note":"Don't delete this file! It's used internally to help with page regeneration."}